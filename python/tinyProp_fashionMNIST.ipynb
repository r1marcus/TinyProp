{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9df2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import torch\n",
    "#import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# CHANGE TINYPROP HYPERPARAMS IN THIS MODULE!!!\n",
    "from tinyProp_modules import TinyPropLinear\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a614357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26a9ae19330>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size_train = 20\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4477a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n",
    "                                                transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n",
    "                                               transforms.Compose([transforms.ToTensor()]))  \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size_train)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size_test)\n",
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                 0: \"T-shirt/Top\",\n",
    "                 1: \"Trouser\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Dress\",\n",
    "                 4: \"Coat\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Shirt\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Bag\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17105f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = TinyPropLinear(28*28, 32, 1)  # last argument being layer_idx (0 for last layer)\n",
    "        self.fc2 = TinyPropLinear(32, 10, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad307909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        fc1_meanBpr[epoch-1] += network.fc1.info.miniBatchBpr\n",
    "        fc1_meanK[epoch-1] += network.fc1.info.miniBatchK\n",
    "        fc2_meanBpr[epoch-1] += network.fc2.info.miniBatchBpr\n",
    "        fc2_meanK[epoch-1] += network.fc2.info.miniBatchK\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()), end ='\\r')\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*batch_size_train) + ((epoch-1)*len(train_loader.dataset)))\n",
    "    print('Train Epoch: {} completed          '.format(epoch))\n",
    "    \n",
    "    fc1_meanBpr[epoch-1] /= len(train_loader.dataset)//batch_size_train\n",
    "    fc1_meanK[epoch-1]   /= len(train_loader.dataset)//batch_size_train\n",
    "    fc2_meanBpr[epoch-1] /= len(train_loader.dataset)//batch_size_train\n",
    "    fc2_meanK[epoch-1]   /= len(train_loader.dataset)//batch_size_train\n",
    "    \n",
    "    \n",
    "def test(network):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6372d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "fc1_meanBpr = torch.zeros([n_epochs])\n",
    "fc1_meanK = torch.zeros([n_epochs])\n",
    "fc2_meanBpr = torch.zeros([n_epochs])\n",
    "fc2_meanK = torch.zeros([n_epochs])\n",
    "\n",
    "#fc1_weights = torch.zeros([n_epochs, 784*32])\n",
    "#fc1_loc_err = torch.zeros([n_epochs, 32])\n",
    "#fc1_Y       = torch.zeros([n_epochs])\n",
    "#fc2_weights = torch.zeros([n_epochs,  32*10])\n",
    "#fc2_loc_err = torch.zeros([n_epochs, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432eea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmaie\\anaconda3\\envs\\quantum\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 2.4303, Accuracy: 1098/10000 (11%)\n",
      "\n",
      "Train Epoch: 1 completed          ]\tLoss: 1.041449\n",
      "Test set: Avg. loss: 1.2552, Accuracy: 6941/10000 (69%)\n",
      "\n",
      "Train Epoch: 2 completed          ]\tLoss: 0.618709\n",
      "Test set: Avg. loss: 2.4894, Accuracy: 6688/10000 (67%)\n",
      "\n",
      "Train Epoch: 3 completed          ]\tLoss: 0.936955\n",
      "Test set: Avg. loss: 1.5130, Accuracy: 7647/10000 (76%)\n",
      "\n",
      "Train Epoch: 4 completed          ]\tLoss: 1.098873\n",
      "Test set: Avg. loss: 1.4026, Accuracy: 7891/10000 (79%)\n",
      "\n",
      "Train Epoch: 5 completed          ]\tLoss: 0.208076\n",
      "Test set: Avg. loss: 2.5297, Accuracy: 7168/10000 (72%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "test(network)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(network, epoch)\n",
    "    test(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "997cbdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2456, 0.1747, 0.1473, 0.1349, 0.1255])\n",
      "tensor([0.3757, 0.2779, 0.2549, 0.2386, 0.2275])\n"
     ]
    }
   ],
   "source": [
    "print(fc1_meanBpr)\n",
    "print(fc2_meanBpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cc04fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
