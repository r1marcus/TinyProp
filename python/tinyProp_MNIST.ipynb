{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9df2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# CHANGE TINYPROP HYPERPARAMS IN THIS MODULE!!!\n",
    "from tinyProp_modules import TinyPropLinear\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a614357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fcd2b74130>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2224490",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8fe8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = TinyPropLinear(28*28, 32, 1)   # last argument being layer_idx (0 for last layer)\n",
    "        self.fc2 = TinyPropLinear(32, 10, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad307909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        fc1_meanBpr[epoch-1] += network.fc1.info.miniBatchBpr\n",
    "        fc1_meanK[epoch-1] += network.fc1.info.miniBatchK\n",
    "        fc2_meanBpr[epoch-1] += network.fc2.info.miniBatchBpr\n",
    "        fc2_meanK[epoch-1] += network.fc2.info.miniBatchK\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()), end ='\\r')\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*batch_size_train) + ((epoch-1)*len(train_loader.dataset)))\n",
    "    print('Train Epoch: {} completed          '.format(epoch))\n",
    "    \n",
    "    fc1_meanBpr[epoch-1] /= len(train_loader.dataset)//batch_size_train\n",
    "    fc1_meanK[epoch-1]   /= len(train_loader.dataset)//batch_size_train\n",
    "    fc2_meanBpr[epoch-1] /= len(train_loader.dataset)//batch_size_train\n",
    "    fc2_meanK[epoch-1]   /= len(train_loader.dataset)//batch_size_train\n",
    "    \n",
    "    \n",
    "def test(network):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a40e9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "fc1_meanBpr = torch.zeros([n_epochs])\n",
    "fc1_meanK = torch.zeros([n_epochs])\n",
    "fc2_meanBpr = torch.zeros([n_epochs])\n",
    "fc2_meanK = torch.zeros([n_epochs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432eea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmaie\\anaconda3\\envs\\quantum\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 3.2852, Accuracy: 1125/10000 (11%)\n",
      "\n",
      "Train Epoch: 1 completed          \tLoss: 0.450822\n",
      "Test set: Avg. loss: 0.4069, Accuracy: 8779/10000 (88%)\n",
      "\n",
      "Train Epoch: 2 completed          \tLoss: 1.422083\n",
      "Test set: Avg. loss: 0.9442, Accuracy: 8523/10000 (85%)\n",
      "\n",
      "Train Epoch: 3 completed          \tLoss: 2.291387\n",
      "Test set: Avg. loss: 1.5549, Accuracy: 8345/10000 (83%)\n",
      "\n",
      "Train Epoch: 4 completed          \tLoss: 1.165662\n",
      "Test set: Avg. loss: 1.7118, Accuracy: 8521/10000 (85%)\n",
      "\n",
      "Train Epoch: 5 completed          \tLoss: 1.257415\n",
      "Test set: Avg. loss: 0.9398, Accuracy: 9172/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "test(network)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(network, epoch)\n",
    "    test(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ba6310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1590, 0.1255, 0.0697, 0.0682, 0.0667])\n",
      "tensor([0.2728, 0.0961, 0.0757, 0.0638, 0.0559])\n"
     ]
    }
   ],
   "source": [
    "print(fc1_meanBpr)\n",
    "print(fc2_meanBpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc04fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a7e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
