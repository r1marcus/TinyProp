{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9df2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a614357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23a64e232d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size_train = 20\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4477a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n",
    "                                                transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n",
    "                                               transforms.Compose([transforms.ToTensor()]))  \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size_train)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size_test)\n",
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                 0: \"T-shirt/Top\",\n",
    "                 1: \"Trouser\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Dress\",\n",
    "                 4: \"Coat\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Shirt\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Bag\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0617a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseLinear(torch.autograd.Function):  \n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, info, bias=None):\n",
    "        # Save inputs in context-object for later use in backwards\n",
    "        ctx.save_for_backward(input, weight, bias) # these are differentiable\n",
    "        ctx.info = info                            # non-differentiable argument\n",
    "        output = input.mm(weight.t())\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        # input   [batchSize, in]\n",
    "        # output  [batchSize, out]\n",
    "        # weights [out, in]\n",
    "        # bias    [out]\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "        # Calculate k (different across batches)\n",
    "        Y = grad_output.abs().sum(1)       # Y[batchSize]\n",
    "        if (torch.max(Y) > ctx.info.Y_max):     # Check if biggest Y of batch is bigger than recorded Y\n",
    "            ctx.info.Y_max = torch.max(Y).item()\n",
    "        bpr = (S_min + Y*(S_max-S_min)/(ctx.info.Y_max))  #TODO add wearoff\n",
    "    \n",
    "        K = torch.tensor(torch.round(grad_output.size(1)*bpr))        # K[batchSize]\n",
    "        K.clamp(1, grad_output.size(1))\n",
    "        # log in layer\n",
    "        ctx.info.miniBatchBpr = torch.mean(bpr)\n",
    "        ctx.info.miniBatchK = torch.mean(K)\n",
    "        K = K.to(torch.int16)\n",
    "        \n",
    "        # create a sparse grad_output tensor. Since k is different across batches, the topK indices\n",
    "        # must be assembled for each batch separately.\n",
    "        col = []\n",
    "        row = []\n",
    "        val = []\n",
    "        for batch,k in enumerate(K):\n",
    "            _, indices = grad_output[batch].abs().topk(k)  # don't use return VALUES since they are abs()!\n",
    "            col.append(indices)\n",
    "            val.append(torch.index_select(grad_output[batch], -1, indices)) # select values from grad_output instead\n",
    "            row += indices.size(0) * [batch]\n",
    "        col = torch.cat(col).detach()\n",
    "        row = torch.Tensor(row)\n",
    "        val = torch.cat(val)\n",
    "        sparse = torch.sparse_coo_tensor(torch.vstack((row,col)), val, grad_output.size())\n",
    "        \n",
    "        # Do the usual bp stuff but use sparse matmul on grad_input and grad_weight\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = torch.sparse.mm(sparse, weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = torch.sparse.mm(sparse.t(), input)  # Gradients are zeroed each batch\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0)\n",
    "        return grad_input, grad_weight, None, grad_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e1d1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackwardsInfo:\n",
    "    def __init__(self):\n",
    "        self.Y_max = 0\n",
    "        self.miniBatchBpr = 0\n",
    "        self.miniBatchK = 0\n",
    "        \n",
    "class TinyPropLinear(nn.Module):\n",
    "    def __init__(self, input_features, output_features, bias=True):\n",
    "        super(TinyPropLinear, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        \n",
    "        # Saving variables like this will pass it by REFERENCE, so changes \n",
    "        # made in backwards are reflected in layer\n",
    "        self.info = BackwardsInfo() \n",
    "        self.weight = nn.Parameter(torch.empty(output_features, input_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(output_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.initialize_parameters()\n",
    "            \n",
    "    def initialize_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.output_features)\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Here the custom linear function is applied\n",
    "        return SparseLinear.apply(input, self.weight, self.info, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5f082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf59d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6a127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83762f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_max = 1\n",
    "S_min = 0\n",
    "zeta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48e373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9909f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseConv2d(torch.autograd.Function):  \n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input, weight, kernel_size, out_channels, dilation, padding, stride, info, bias=None):\n",
    "        # Save inputs in context-object for later use in backwards\n",
    "        ctx.save_for_backward(input, weight, bias) # these are differentiable\n",
    "        \n",
    "        # Save non-differentiable argument(s)\n",
    "        ctx.info = info \n",
    "        #ctx.dilation = dilation\n",
    "        #ctx.padding = padding\n",
    "        #ctx.stride = stride\n",
    "        \n",
    "        \n",
    "        # x [batchSize, in_channels, width, height]\n",
    "        width = ((x.shape[2] + 2*padding[0] - dilation[0]*(kernel_size - 1) - 1) // stride[0]) + 1\n",
    "        height= ((x.shape[3] + 2*padding[1] - dilation[1]*(kernel_size - 1) - 1) // stride[1]) + 1\n",
    "     \n",
    "        windows = F.unfold(x, kernel_size=(kernel_size, kernel_size), padding=padding, dilation=dilation, stride=stride)\n",
    "        windows = windows.transpose(1, 2).contiguous().view(-1, x.shape[1], kernel_size*kernel_size)\n",
    "        windows = windows.transpose(0, 1)\n",
    "        \n",
    "        print(width)\n",
    "        print(height)\n",
    "        print(windows.shape)\n",
    "        \n",
    "        output = torch.zeros([x.shape[0]*out_channels, width, height], dtype=torch.float32, device=device)\n",
    "\n",
    "        # Loop over channels\n",
    "        for channel in range(x.shape[1]):\n",
    "            for outChannel in range(out_channels):\n",
    "                res = torch.matmul(windows[channel], weight[outChannel][channel]) \n",
    "                res = res.view(-1, width, height)\n",
    "                output[outChannel * res.shape[0] : (outChannel + 1) * res.shape[0]] += res\n",
    "                \n",
    "        output = output.view(x.shape[0], out_channels, width, height)\n",
    "       \n",
    "        #if bias is not None:\n",
    "            #output += bias.unsqueeze(0).expand_as(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        # input   [batchSize, in]\n",
    "        # output  [batchSize, out]\n",
    "        # weights [out, in]\n",
    "        # bias    [out]\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "        # Calculate k (different across batches)\n",
    "        Y = grad_output.abs().sum(1)       # Y[batchSize]\n",
    "        if (torch.max(Y) > ctx.info.Y_max):     # Check if biggest Y of batch is bigger than recorded Y\n",
    "            ctx.info.Y_max = torch.max(Y).item()\n",
    "        bpr = (S_min + Y*(S_max-S_min)/(ctx.info.Y_max))  #TODO add wearoff\n",
    "    \n",
    "        K = torch.tensor(torch.round(grad_output.size(1)*bpr))        # K[batchSize]\n",
    "        K.clamp(1, grad_output.size(1))\n",
    "        # log in layer\n",
    "        ctx.info.miniBatchBpr = torch.mean(bpr)\n",
    "        ctx.info.miniBatchK = torch.mean(K)\n",
    "        K = K.to(torch.int16)\n",
    "        \n",
    "        # create a sparse grad_output tensor. Since k is different across batches, the topK indices\n",
    "        # must be assembled for each batch separately.\n",
    "        col = []\n",
    "        row = []\n",
    "        val = []\n",
    "        for batch,k in enumerate(K):\n",
    "            _, indices = grad_output[batch].abs().topk(k)  # don't use return VALUES since they are abs()!\n",
    "            col.append(indices)\n",
    "            val.append(torch.index_select(grad_output[batch], -1, indices)) # select values from grad_output instead\n",
    "            row += indices.size(0) * [batch]\n",
    "        col = torch.cat(col).detach()\n",
    "        row = torch.Tensor(row)\n",
    "        val = torch.cat(val)\n",
    "        sparse = torch.sparse_coo_tensor(torch.vstack((row,col)), val, grad_output.size())\n",
    "        \n",
    "        # Do the usual bp stuff but use sparse matmul on grad_input and grad_weight\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = torch.sparse.mm(sparse, weight)\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = torch.sparse.mm(sparse.t(), input)  # Gradients are zeroed each batch\n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0)\n",
    "        return grad_input, grad_weight, None, None, None, None, None, None, grad_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "050b4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyPropConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1, bias=True):\n",
    "        super(TinyPropConv2d, self).__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.dilation = (dilation, dilation)\n",
    "        self.padding = (padding, padding)\n",
    "        self.stride = (stride, stride)\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        # Saving variables like this will pass it by REFERENCE, so changes \n",
    "        # made in backwards are reflected in layer\n",
    "        self.info = BackwardsInfo() \n",
    "        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size * kernel_size))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Here the custom conv2d function is applied\n",
    "        return SparseConv2d.apply(input, self.weight, self.kernel_size, self.out_channels, self.dilation, self.padding, self.stride, self.info, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d60fc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n",
      "torch.Size([3, 484, 9])\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "conv = TinyPropConv2d(3, 1, 3)\n",
    "x = torch.randn(1, 3, 24, 24)\n",
    "out = conv(x)\n",
    "#out.mean().backward()\n",
    "#print(conv.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de20377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec0ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17105f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_max = 1\n",
    "S_min = 0\n",
    "zeta = 1\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = TinyPropLinear(28*28, 32)\n",
    "        self.fc2 = TinyPropLinear(32, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad307909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        fc1_meanBpr[epoch-1] += network.fc1.info.miniBatchBpr\n",
    "        fc1_meanK[epoch-1] += network.fc1.info.miniBatchK\n",
    "        fc2_meanBpr[epoch-1] += network.fc2.info.miniBatchBpr\n",
    "        fc2_meanK[epoch-1] += network.fc2.info.miniBatchK\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()), end ='\\r')\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*batch_size_train) + ((epoch-1)*len(train_loader.dataset)))\n",
    "    print('Train Epoch: {} completed          '.format(epoch))\n",
    "    \n",
    "    fc1_meanBpr[epoch-1] /= len(train_loader.dataset)//batch_size_train\n",
    "    fc1_meanK[epoch-1]   /= len(train_loader.dataset)//batch_size_train\n",
    "    fc2_meanBpr[epoch-1] /= len(train_loader.dataset)//batch_size_train\n",
    "    fc2_meanK[epoch-1]   /= len(train_loader.dataset)//batch_size_train\n",
    "    \n",
    "    \n",
    "def test(network):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6372d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "fc1_meanBpr = torch.zeros([n_epochs])\n",
    "fc1_meanK = torch.zeros([n_epochs])\n",
    "fc2_meanBpr = torch.zeros([n_epochs])\n",
    "fc2_meanK = torch.zeros([n_epochs])\n",
    "\n",
    "#fc1_weights = torch.zeros([n_epochs, 784*32])\n",
    "#fc1_loc_err = torch.zeros([n_epochs, 32])\n",
    "#fc1_Y       = torch.zeros([n_epochs])\n",
    "#fc2_weights = torch.zeros([n_epochs,  32*10])\n",
    "#fc2_loc_err = torch.zeros([n_epochs, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432eea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 2.5484, Accuracy: 730/10000 (7%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.661971\r",
      "Train Epoch: 1 [200/60000 (0%)]\tLoss: 2.157662\r",
      "Train Epoch: 1 [400/60000 (1%)]\tLoss: 1.980443\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmaie\\anaconda3\\envs\\quantum\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 completed          ]\tLoss: 2.028627\n",
      "Test set: Avg. loss: 1.5996, Accuracy: 6550/10000 (66%)\n",
      "\n",
      "Train Epoch: 2 completed          ]\tLoss: 1.063643\n",
      "Test set: Avg. loss: 1.5513, Accuracy: 7175/10000 (72%)\n",
      "\n",
      "Train Epoch: 3 completed          ]\tLoss: 1.171235\n",
      "Test set: Avg. loss: 1.6653, Accuracy: 7532/10000 (75%)\n",
      "\n",
      "Train Epoch: 4 completed          ]\tLoss: 1.314612\n",
      "Test set: Avg. loss: 2.4600, Accuracy: 7026/10000 (70%)\n",
      "\n",
      "Train Epoch: 5 completed          ]\tLoss: 0.604967\n",
      "Test set: Avg. loss: 2.0251, Accuracy: 7408/10000 (74%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "test(network)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(network, epoch)\n",
    "    test(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "997cbdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2403, 0.1675, 0.1461, 0.1276, 0.1191])\n",
      "tensor([0.3646, 0.2760, 0.2558, 0.2404, 0.2309])\n"
     ]
    }
   ],
   "source": [
    "print(fc1_meanBpr)\n",
    "print(fc2_meanBpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cc04fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1f878c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGradients(gradients, end, num_bins, num_samples):\n",
    "    bins = np.linspace(0, end, num_bins+1)\n",
    "    X, Y = np.meshgrid(bins[:num_bins], np.arange(0, num_samples))\n",
    "    Z = np.empty([num_samples, num_bins])\n",
    "\n",
    "    for i,sample in enumerate(gradients):\n",
    "        hist, edges = np.histogram(sample, bins=bins)\n",
    "        #print('hist')\n",
    "        #print(sample)\n",
    "        #print(hist)\n",
    "        #print(edges)\n",
    "        Z[i] = hist\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none')\n",
    "    ax.set_title('Surface plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82a73079",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotGradients(fc1_loc_err, 5, 25, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9132a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
